import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np

# Configuration
IMG_SIZE = (600, 600)  # EfficientNetB7 prefers larger images
BATCH_SIZE = 16  # Reduced due to larger model size

# Data generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    os.path.join(base_dir, 'train'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(base_dir, 'val'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

# Model architecture - EfficientNetB7
base_model = tf.keras.applications.EfficientNetB7(
    weights='imagenet',
    include_top=False,
    input_shape=(600, 600, 3)
)

# Freeze the base model
base_model.trainable = False

# Add custom layers
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(1024, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(3, activation='softmax')  # Change 3 to your number of classes
])

# Training with lower learning rate
model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Callbacks
early_stop = EarlyStopping(
    monitor='val_accuracy',
    patience=10,
    restore_best_weights=True
)

checkpoint = ModelCheckpoint(
    'efficientnetb7_best.keras',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max'
)

# Training
history = model.fit(
    train_generator,
    epochs=50,
    validation_data=val_generator,
    callbacks=[early_stop, checkpoint],
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    validation_steps=val_generator.samples // BATCH_SIZE
)

# Evaluation
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    os.path.join(base_dir, 'test'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

test_loss, test_acc = model.evaluate(test_generator)
print(f"\nEfficientNetB7 Test Accuracy: {test_acc:.4f}")

# Visualization
output_dir = '/content/drive/MyDrive/ML'
os.makedirs(output_dir, exist_ok=True)

# 1. Plot training history
plt.figure(figsize=(14, 6))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], 'b-', linewidth=2, label='Train Accuracy')
plt.plot(history.history['val_accuracy'], 'r-', linewidth=2, label='Validation Accuracy')
plt.title('EfficientNetB7 Accuracy Curves', fontsize=14)
plt.ylabel('Accuracy', fontsize=12)
plt.xlabel('Epoch', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.5)

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], 'b-', linewidth=2, label='Train Loss')
plt.plot(history.history['val_loss'], 'r-', linewidth=2, label='Validation Loss')
plt.title('EfficientNetB7 Loss Curves', fontsize=14)
plt.ylabel('Loss', fontsize=12)
plt.xlabel('Epoch', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.5)

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'efficientnetb7_training_curves.pdf'), dpi=300, bbox_inches='tight')
plt.show()

# 2. Confusion Matrix
test_generator.reset()
y_true = test_generator.classes
y_pred = model.predict(test_generator, verbose=1)
y_pred = np.argmax(y_pred, axis=1)

class_names = list(train_generator.class_indices.keys())
cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrBr',
            xticklabels=class_names,
            yticklabels=class_names,
            annot_kws={'size': 12})

plt.title('EfficientNetB7 Confusion Matrix', fontsize=14)
plt.ylabel('True Label', fontsize=12)
plt.xlabel('Predicted Label', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'efficientnetb7_confusion_matrix.pdf'), dpi=300, bbox_inches='tight')
plt.show()

print(f"\nVisualizations saved to {output_dir}")

# Model Summary
print("\nModel Architecture Summary:")
model.summary()
