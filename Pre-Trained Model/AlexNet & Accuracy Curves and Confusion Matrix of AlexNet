import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np

# Configuration
IMG_SIZE = (227, 227)  # AlexNet original input size
BATCH_SIZE = 32

# Data generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    os.path.join(base_dir, 'train'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    os.path.join(base_dir, 'val'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

# Custom AlexNet implementation (since Keras doesn't have a built-in AlexNet)
def create_alexnet(num_classes):
    model = models.Sequential([
        # 1st Convolutional Layer
        layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(227, 227, 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),
        
        # 2nd Convolutional Layer
        layers.Conv2D(256, (5, 5), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),
        
        # 3rd Convolutional Layer
        layers.Conv2D(384, (3, 3), padding='same', activation='relu'),
        
        # 4th Convolutional Layer
        layers.Conv2D(384, (3, 3), padding='same', activation='relu'),
        
        # 5th Convolutional Layer
        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),
        layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),
        
        # Flatten
        layers.Flatten(),
        
        # 1st Fully Connected Layer
        layers.Dense(4096, activation='relu'),
        layers.Dropout(0.5),
        
        # 2nd Fully Connected Layer
        layers.Dense(4096, activation='relu'),
        layers.Dropout(0.5),
        
        # Output Layer
        layers.Dense(num_classes, activation='softmax')
    ])
    return model

# Create model
model = create_alexnet(num_classes=3)  # Change 3 to your number of classes

# Training
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    epochs=50,  # AlexNet often needs more epochs
    validation_data=val_generator,
    callbacks=[
        EarlyStopping(patience=7, restore_best_weights=True),
        ModelCheckpoint('alexnet_best.keras', save_best_only=True)
    ]
)

# Evaluation
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    os.path.join(base_dir, 'test'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

test_loss, test_acc = model.evaluate(test_generator)
print(f"AlexNet Test Accuracy: {test_acc:.4f}")

# Visualization
output_dir = '/content/drive/MyDrive/ML'
os.makedirs(output_dir, exist_ok=True)

# 1. Training history
plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], 'go-', label='Train Accuracy')
plt.plot(history.history['val_accuracy'], 'ro-', label='Validation Accuracy')
plt.title('Accuracy Curves: AlexNet')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], 'go-', label='Train Loss')
plt.plot(history.history['val_loss'], 'ro-', label='Validation Loss')
plt.title('Loss Curves: AlexNet')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()

plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'training_curves_alexnet.pdf'))
plt.show()

# 2. Confusion matrix
test_generator.reset()
y_true = test_generator.classes
y_pred = model.predict(test_generator, steps=len(test_generator), verbose=1)
y_pred = np.argmax(y_pred, axis=1)

class_names = list(train_generator.class_indices.keys())

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges',
            xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix: AlexNet')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig(os.path.join(output_dir, 'confusion_matrix_alexnet.pdf'))
plt.show()

print(f"Plots saved to {output_dir}")
